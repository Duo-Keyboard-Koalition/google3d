{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b59aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a66526db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre - trained bert model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertForQuestionAnswering\n",
    "model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased-distilled-squad')\n",
    "question = \"Who created distilbert?\"\n",
    "context = \"DistilBERT works by using a knowledge distillation process, where the outputs from a large, pre-trained BERT model are used to train a smaller, faster, and more compact model. In the distillation process, the large pre-trained model acts as a teacher model and the smaller, distilled model acts as a student model.\"\n",
    "inputs = tokenizer(question, context, return_tensors='pt')\n",
    "outputs = model(**inputs)\n",
    "start_scores = outputs.start_logits\n",
    "end_scores = outputs.end_logits\n",
    "answer_start = torch.argmax(start_scores)\n",
    "answer_end = torch.argmax(end_scores)\n",
    "answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end+1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3465bb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre - trained bert model\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47459968-1844-4a98-b7e9-28f335c41bc5",
   "metadata": {},
   "source": [
    "# Now I want to Use Bert for Language Translation Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58ed9ffe-8630-4998-88cf-974befeed6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.040800221264362335,\n",
       "  'token': 37859,\n",
       "  'token_str': 'virtual',\n",
       "  'sequence': \"Hello I'm a virtual model.\"},\n",
       " {'score': 0.020016005262732506,\n",
       "  'token': 22185,\n",
       "  'token_str': 'big',\n",
       "  'sequence': \"Hello I'm a big model.\"},\n",
       " {'score': 0.018680503591895103,\n",
       "  'token': 31178,\n",
       "  'token_str': 'Hello',\n",
       "  'sequence': \"Hello I'm a Hello model.\"},\n",
       " {'score': 0.017396600916981697,\n",
       "  'token': 13192,\n",
       "  'token_str': 'model',\n",
       "  'sequence': \"Hello I'm a model model.\"},\n",
       " {'score': 0.014229835942387581,\n",
       "  'token': 43477,\n",
       "  'token_str': 'perfect',\n",
       "  'sequence': \"Hello I'm a perfect model.\"}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model='distilbert-base-multilingual-cased')\n",
    "unmasker(\"Hello I'm a [MASK] model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "780d63a2-fe25-4139-9efc-f223aba8eb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8572b82724b8476fa2e06f25544d621d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/3.71M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc7c0e2a60a43549adb602d6bf0e8eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d048111c20264487a29ffd999331dec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/1.14k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'Bonjour, comment vous êtes-vous ?'}]\n",
      "[{'translation_text': 'Hello how is it?'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "model = \"facebook/m2m100_418M\"\n",
    "translator = pipeline(\"translation_en_to_fr\", model=model)\n",
    "result = translator(\"Hello, how are you?\")\n",
    "print(result)\n",
    "\n",
    "translator = pipeline(\"translation_fr_to_en\", model=model)\n",
    "result = translator(\"Bonjour comment ça va?\")\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0df49276",
   "metadata": {},
   "source": [
    "### Now I can wrap the code into a function to be used in Kataros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41715c35-17b9-4cda-bf6b-592817c2a0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'Bonjour, comment vous êtes-vous ?'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "def translate(source_lang, target_lang, text):\n",
    "    translation = f\"translation_{source_lang}_to_{target_lang}\"\n",
    "    model_name = \"facebook/m2m100_418M\"\n",
    "    translator = pipeline(translation, model=model_name)\n",
    "    result = translator(text, src_lang=source_lang, tgt_lang=target_lang)\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "source_lang = \"en\"\n",
    "target_lang = \"fr\"\n",
    "text = \"Hello, how are you?\"\n",
    "translation = translate(source_lang, target_lang, text)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cbcd916-65e8-4083-a0fe-01aa3eeea4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': '你好,你怎么样?'}]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "source_lang = \"en\"\n",
    "target_lang = \"zh\"\n",
    "text = \"Hello, how are you?\"\n",
    "translation = translate(source_lang, target_lang, text)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c520648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "source_lang = \"en\"\n",
    "target_lang = \"zh\"\n",
    "text = \"Hello, how are you?\"\n",
    "translation = translate(source_lang, target_lang, text)\n",
    "print(translation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
