{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06b59aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\darcy\\pycharmprojects\\kataros\\venv\\lib\\site-packages (4.31.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\darcy\\pycharmprojects\\kataros\\venv\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\darcy\\pycharmprojects\\kataros\\venv\\lib\\site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\darcy\\pycharmprojects\\kataros\\venv\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\darcy\\pycharmprojects\\kataros\\venv\\lib\\site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\darcy\\pycharmprojects\\kataros\\venv\\lib\\site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\darcy\\pycharmprojects\\kataros\\venv\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\darcy\\pycharmprojects\\kataros\\venv\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\darcy\\pycharmprojects\\kataros\\venv\\lib\\site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\darcy\\pycharmprojects\\kataros\\venv\\lib\\site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\darcy\\pycharmprojects\\kataros\\venv\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\darcy\\pycharmprojects\\kataros\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\darcy\\pycharmprojects\\kataros\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\darcy\\pycharmprojects\\kataros\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\darcy\\pycharmprojects\\kataros\\venv\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\darcy\\pycharmprojects\\kataros\\venv\\lib\\site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\darcy\\pycharmprojects\\kataros\\venv\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\darcy\\pycharmprojects\\kataros\\venv\\lib\\site-packages (from requests->transformers) (3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a66526db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre - trained bert model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertForQuestionAnswering\n",
    "model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased-distilled-squad')\n",
    "question = \"Who created distilbert?\"\n",
    "context = \"DistilBERT works by using a knowledge distillation process, where the outputs from a large, pre-trained BERT model are used to train a smaller, faster, and more compact model. In the distillation process, the large pre-trained model acts as a teacher model and the smaller, distilled model acts as a student model.\"\n",
    "inputs = tokenizer(question, context, return_tensors='pt')\n",
    "outputs = model(**inputs)\n",
    "start_scores = outputs.start_logits\n",
    "end_scores = outputs.end_logits\n",
    "answer_start = torch.argmax(start_scores)\n",
    "answer_end = torch.argmax(end_scores)\n",
    "answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end+1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3465bb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre - trained bert model\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47459968-1844-4a98-b7e9-28f335c41bc5",
   "metadata": {},
   "source": [
    "# Now I want to Use Bert for Language Translation Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58ed9ffe-8630-4998-88cf-974befeed6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.040800221264362335,\n",
       "  'token': 37859,\n",
       "  'token_str': 'virtual',\n",
       "  'sequence': \"Hello I'm a virtual model.\"},\n",
       " {'score': 0.020016005262732506,\n",
       "  'token': 22185,\n",
       "  'token_str': 'big',\n",
       "  'sequence': \"Hello I'm a big model.\"},\n",
       " {'score': 0.018680503591895103,\n",
       "  'token': 31178,\n",
       "  'token_str': 'Hello',\n",
       "  'sequence': \"Hello I'm a Hello model.\"},\n",
       " {'score': 0.017396600916981697,\n",
       "  'token': 13192,\n",
       "  'token_str': 'model',\n",
       "  'sequence': \"Hello I'm a model model.\"},\n",
       " {'score': 0.014229835942387581,\n",
       "  'token': 43477,\n",
       "  'token_str': 'perfect',\n",
       "  'sequence': \"Hello I'm a perfect model.\"}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model='distilbert-base-multilingual-cased')\n",
    "unmasker(\"Hello I'm a [MASK] model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "780d63a2-fe25-4139-9efc-f223aba8eb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'Bonjour, comment êtes-vous?'}]\n",
      "[{'translation_text': 'Bonjour, comment ça va?'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "model = \"t5-base\"\n",
    "translator = pipeline(\"translation_en_to_fr\", model=model)\n",
    "result = translator(\"Hello, how are you?\")\n",
    "print(result)\n",
    "\n",
    "translator = pipeline(\"translation_fr_to_en\", model=model)\n",
    "result = translator(\"Bonjour comment ça va?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41715c35-17b9-4cda-bf6b-592817c2a0e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The task defaults can't be correctly selected. You probably meant \"translation_XX_to_YY\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m translator \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtranslation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\kataros\\venv\\lib\\site-packages\\transformers\\pipelines\\__init__.py:751\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;66;03m# Use default model/config/tokenizer for the task if no model is provided\u001b[39;00m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    750\u001b[0m     \u001b[38;5;66;03m# At that point framework might still be undetermined\u001b[39;00m\n\u001b[1;32m--> 751\u001b[0m     model, default_revision \u001b[38;5;241m=\u001b[39m \u001b[43mget_default_model_and_revision\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargeted_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    752\u001b[0m     revision \u001b[38;5;241m=\u001b[39m revision \u001b[38;5;28;01mif\u001b[39;00m revision \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m default_revision\n\u001b[0;32m    753\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    754\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo model was supplied, defaulted to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and revision\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    755\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    756\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a pipeline without specifying a model name and revision in production is not recommended.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    757\u001b[0m     )\n",
      "File \u001b[1;32m~\\PycharmProjects\\kataros\\venv\\lib\\site-packages\\transformers\\pipelines\\base.py:394\u001b[0m, in \u001b[0;36mget_default_model_and_revision\u001b[1;34m(targeted_task, framework, task_options)\u001b[0m\n\u001b[0;32m    390\u001b[0m     default_models \u001b[38;5;241m=\u001b[39m targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;66;03m# XXX This error message needs to be updated to be more generic if more tasks are going to become\u001b[39;00m\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;66;03m# parametrized\u001b[39;00m\n\u001b[1;32m--> 394\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe task defaults can\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt be correctly selected. You probably meant \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranslation_XX_to_YY\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    397\u001b[0m     framework \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: The task defaults can't be correctly selected. You probably meant \"translation_XX_to_YY\""
     ]
    }
   ],
   "source": [
    "translator = pipeline(\"translation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbcd916-65e8-4083-a0fe-01aa3eeea4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
